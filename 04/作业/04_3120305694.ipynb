{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import  random\n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "#定义要爬取的微博大V的微博ID\n",
    "import requests\n",
    "import time\n",
    "id=(input(\"请输入要抓的微博uid:\"))\n",
    "\n",
    "na='a'\n",
    "#设置代理IP\n",
    "\n",
    "iplist=['112.228.161.57:8118','125.126.164.21:34592','122.72.18.35:80','163.125.151.124:9999','114.250.25.19:80']\n",
    "\n",
    "proxy_addr=\"125.126.164.21:34592\"\n",
    "\n",
    "#定义页面打开函数\n",
    "def use_proxy(url,proxy_addr):\n",
    "    req=urllib.request.Request(url)\n",
    "    req.add_header(\"User-Agent\",\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0\")\n",
    "    proxy=urllib.request.ProxyHandler({'http':random.choice(iplist)})\n",
    "    opener=urllib.request.build_opener(proxy,urllib.request.HTTPHandler)\n",
    "    urllib.request.install_opener(opener)\n",
    "    data=urllib.request.urlopen(req).read().decode('utf-8','ignore')\n",
    "    return data\n",
    "\n",
    "#获取微博主页的containerid，爬取微博内容时需要此id\n",
    "def get_containerid(url):\n",
    "    data=use_proxy(url,random.choice(iplist))\n",
    "    content=json.loads(data).get('data')\n",
    "    for data in content.get('tabsInfo').get('tabs'):\n",
    "        if(data.get('tab_type')=='weibo'):\n",
    "            containerid=data.get('containerid')\n",
    "    return containerid\n",
    "\n",
    "#获取微博大V账号的用户基本信息，如：微博昵称、微博地址、微博头像、关注人数、粉丝数、性别、等级等\n",
    "def get_userInfo(id):\n",
    "    url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id\n",
    "    data=use_proxy(url,random.choice(iplist))\n",
    "    content=json.loads(data).get('data')\n",
    "    profile_image_url=content.get('userInfo').get('profile_image_url')\n",
    "    description=content.get('userInfo').get('description')\n",
    "    profile_url=content.get('userInfo').get('profile_url')\n",
    "    verified=content.get('userInfo').get('verified')\n",
    "    guanzhu=content.get('userInfo').get('follow_count')\n",
    "    name=content.get('userInfo').get('screen_name')\n",
    "    na=name\n",
    "    fensi=content.get('userInfo').get('followers_count')\n",
    "    gender=content.get('userInfo').get('gender')\n",
    "    urank=content.get('userInfo').get('urank')\n",
    "    print(\"微博昵称：\"+name+\"\\n\"+\"微博主页地址：\"+profile_url+\"\\n\"+\"微博头像地址：\"+profile_image_url+\"\\n\"+\"是否认证：\"+str(verified)+\"\\n\"+\"微博说明：\"+description+\"\\n\"+\"关注人数：\"+str(guanzhu)+\"\\n\"+\"粉丝数：\"+str(fensi)+\"\\n\"+\"性别：\"+gender+\"\\n\"+\"微博等级：\"+str(urank)+\"\\n\")\n",
    "\n",
    "\n",
    "#获取微博内容信息,并保存到文本中，内容包括：每条微博的内容、微博详情页面地址、点赞数、评论数、转发数等\n",
    "def get_weibo(id,file):\n",
    "    i=1\n",
    "    Directory = 'D:\\python\\myspoils\\weibo\\MM\\s'\n",
    "    while True:\n",
    "        url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id\n",
    "        weibo_url='https://m.weibo.cn/api/container/getIndex?type=uid&value='+id+'&containerid='+get_containerid(url)+'&page='+str(i)\n",
    "        try:\n",
    "            data=use_proxy(weibo_url,random.choice(iplist))\n",
    "            content=json.loads(data).get('data')\n",
    "            cards=content.get('cards')\n",
    "            if(len(cards)>0):\n",
    "                for j in range(len(cards)):\n",
    "                    print(\"-----正在爬取第\"+str(i)+\"页，第\"+str(j)+\"条微博------\")\n",
    "                    card_type=cards[j].get('card_type')\n",
    "                    if(card_type==9):\n",
    "                        mblog=cards[j].get('mblog')\n",
    "                        #print(mblog)\n",
    "                        #print(str(mblog).find(\"转发微博\"))\n",
    "                        if str(mblog).find('retweeted_status')  == -1:\n",
    "                            if str(mblog).find('original_pic') !=-1:\n",
    "                                img_url=re.findall(r\"'url': '(.+?)'\", str(mblog))##pics(.+?)\n",
    "                                n = 1\n",
    "                                timename = str(time.time())\n",
    "                                timename = timename.replace('.', '')\n",
    "                                timename = timename[7:]#利用时间作为独特的名称\n",
    "                                for url in img_url:\n",
    "                                    print('第' + str(n) + ' 张', end='')\n",
    "                                    with open(Directory + timename+url[-5:], 'wb') as f:\n",
    "                                        f.write(requests.get(url).content)\n",
    "                                    print('...OK!')\n",
    "                                    n = n + 1\n",
    "                               # if( n%3==0 ):  ##延迟爬取，防止截流\n",
    "                                  #  time.sleep(3)\n",
    "\n",
    "\n",
    "                        attitudes_count=mblog.get('attitudes_count')\n",
    "                        comments_count=mblog.get('comments_count')\n",
    "                        created_at=mblog.get('created_at')\n",
    "                        reposts_count=mblog.get('reposts_count')\n",
    "                        scheme=cards[j].get('scheme')\n",
    "                        text=mblog.get('text')\n",
    "                        with open(file,'a',encoding='utf-8') as fh:\n",
    "                            fh.write(\"----第\"+str(i)+\"页，第\"+str(j)+\"条微博----\"+\"\\n\")\n",
    "                            fh.write(\"微博地址：\"+str(scheme)+\"\\n\"+\"发布时间：\"+str(created_at)+\"\\n\"+\"微博内容：\"+text+\"\\n\"+\"点赞数：\"+str(attitudes_count)+\"\\n\"+\"评论数：\"+str(comments_count)+\"\\n\"+\"转发数：\"+str(reposts_count)+\"\\n\")\n",
    "                i+=1\n",
    "            else:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    file='D:\\python\\myspoils\\weibo\\\\'+id+\".txt\"\n",
    "    get_userInfo(id)\n",
    "    get_weibo(id,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "def get_url_bv(bv):\n",
    "    headerss={\"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36 Maxthon/5.0\"}\n",
    "    def download_url(url,name,jia):\n",
    "        path='download/'+jia+'/'#保存地址及名称\n",
    "        r=requests.get(url,headers=headerss,stream=True)\n",
    "        types=\".flv\"\n",
    "        with open(path+name+types,'wb') as f:\n",
    "            f.write(r.content)\n",
    "            f.close()\n",
    "        print(name+'文件保存成功')\n",
    "    def mktdir(title):\n",
    "        if os.path.exists(\"download/\"+title)==True:\n",
    "            print(\"文件夹已存在!\")\n",
    "        else:\n",
    "            os.makedirs('download/'+title)\n",
    "    r=requests.get(\"https://api.bilibili.com/x/web-interface/view?bvid=\"+bv,headers=headerss)\n",
    "    j=json.loads(r.text)\n",
    "    if(j[\"code\"]==0):\n",
    "        title=j[\"data\"][\"title\"]\n",
    "        mktdir(title)\n",
    "        ciddick=j[\"data\"][\"pages\"]\n",
    "        lens=len(ciddick)\n",
    "        while lens!=0:\n",
    "            headerss={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\"}\n",
    "            cid=ciddick[lens-1][\"cid\"]\n",
    "            name=ciddick[lens-1][\"part\"] \n",
    "            r=requests.get(\"https://api.bilibili.com/x/player/playurl?cid=\"+str(cid)+\"&bvid=\"+bv+\"&otype=json\",headers=headerss)\n",
    "            j=json.loads(r.text)\n",
    "            linshi=j[\"data\"][\"durl\"]\n",
    "            url=linshi[0][\"url\"]\n",
    "            headerss={\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\",\"Referer\":\"https://www.bilibili.com/video/\"+bv}\n",
    "            download_url(url,name,title)\n",
    "            lens=lens-1\n",
    "        return 0\n",
    "    else:\n",
    "        print(\"error:\",j[\"code\"],\" message:\",j[\"message\"])\n",
    "        return j[\"code\"]\n",
    "\n",
    "size=input(\"输入bv号个数:\")\n",
    "size=int(size)\n",
    "for i in range(0,size):\n",
    "    value=input(\"bv\"+str(i)+\":\")\n",
    "    get_url_bv(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import datetime\n",
    "from fake_useragent import UserAgent\n",
    "user_agent = [\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"\n",
    "    ]#这里可以优化，使用导入伪造头部信息的模块 from fake_useragent import UserAgent\n",
    "start_time = datetime.datetime.now()\n",
    "def  Grab_barrage(date):\n",
    "    # 伪装请求头\n",
    "    headers = {\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\": \"cors\",\n",
    "        \"sec-fetch-site\": \"same-site\",\n",
    "        \"origin\": \"https://www.bilibili.com\",\n",
    "        \"referer\": \"https://www.bilibili.com/video/BV1Z5411Y7or?from=search&seid=8575656932289970537\",\n",
    "        \"cookie\": \"_uuid=0EBFC9C8-19C3-66CC-4C2B-6A5D8003261093748infoc; buvid3=4169BA78-DEBD-44E2-9780-B790212CCE76155837infoc; sid=ae7q4ujj; DedeUserID=501048197; DedeUserID__ckMd5=1d04317f8f8f1021; SESSDATA=e05321c1%2C1607514515%2C52633*61; bili_jct=98edef7bf9e5f2af6fb39b7f5140474a; CURRENT_FNVAL=16; rpdid=|(JJmlY|YukR0J'ulmumY~u~m; LIVE_BUVID=AUTO4315952457375679; CURRENT_QUALITY=80; bp_video_offset_501048197=417696779406748720; bp_t_offset_501048197=417696779406748720; PVID=2\",\n",
    "        \"user-agent\": random.choice(user_agent),\n",
    "        #也可以使用\t \"user-agent\": UserAgent().random\n",
    "    }\n",
    "    # 构造url访问   需要用到的参数\n",
    "    params = {\n",
    "        'type': 1,\n",
    "        'oid': '262657924',#这里改成你自己需要爬取视频的cid，通过F12去找到该相关参数\t但是我不知道为啥前面的key是 oid\n",
    "        'date': date#这个时间根据弹幕的历史数量来，起始时间和结束时间都可以自定义\n",
    "    }\n",
    "    # 发送请求  获取响应\n",
    "    response = requests.get(url, params=params, headers=headers)#get请求，params是添加在url后面的附带链接，具体自行百度\n",
    "    # print(response.encoding)   重新设置编码\n",
    "    response.encoding = 'utf-8'\n",
    "    # print(response.text)\n",
    "    # 正则匹配提取数据\n",
    "    comment = re.findall('<d p=\".*?\">(.*?)</d>', response.text)\n",
    "    # 将每条弹幕数据写入txt\n",
    "    with open('barrages1.txt', 'a+') as f:\n",
    "        for con in comment:\n",
    "            f.write(con + '\\n')\n",
    "    time.sleep(random.randint(1, 3))   # 休眠\n",
    "    def main():\n",
    "    # 开多线程爬取   提高爬取效率\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        executor.map(Grab_barrage, date_list)\n",
    "    # 计算所用时间\n",
    "    delta = (datetime.datetime.now() - start_time).total_seconds()\n",
    "    print(f'用时：{delta}s')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 目标url\n",
    "    url = \"https://api.bilibili.com/x/v2/dm/history\"#弹幕池固定url\n",
    "    start = '20200601'#自定义\n",
    "    end = '20201205'#自定义\n",
    "    # 生成时间序列\n",
    "    date_list = [x for x in pd.date_range(start, end).strftime('%Y-%m-%d')]\n",
    "    count = 0\n",
    "    # 调用主函数\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider(self,startUrl):\n",
    "    browser=webdriver.PhantomJS()\n",
    "    browser.set_window_size(1280,2400) #获取屏幕大小\n",
    "    proxyList=[]\n",
    "    browser.get(startUrl)\n",
    "    browser.implicitly_wait(5)\n",
    "\n",
    "    #块\n",
    "    divs=browser.find_elements_by_xpath('//ul[@class=\"rank-list\"]/li')\n",
    "    #print(div)\n",
    "    for div in divs:\n",
    "        item=Item()\n",
    "        #排名\n",
    "        item.num=div.find_element_by_xpath('.//div[@class=\"num\"]').text  \n",
    "        print(item.num)\n",
    "        #标题\n",
    "        item.title=div.find_element_by_xpath('.//div[@class=\"info\"]/a').text\n",
    "        print(item.title)\n",
    "        #作者\n",
    "        item.author=div.find_element_by_xpath('.//div[@class=\"detail\"]/a/span').text\n",
    "        print(item.author)\n",
    "        #播放量\n",
    "        n=div.find_elements_by_xpath('.//div[@class=\"detail\"]/span')\n",
    "        item.bf=n[0].text\n",
    "        print(item.bf)\n",
    "        #弹幕量\n",
    "        item.count=n[1].text\n",
    "        print(item.count)\n",
    "        proxyList.append(item)\n",
    "    browser.quit()\n",
    "    return proxyList\n",
    "\n",
    "def saveFile(self,fileName,proxyList):\n",
    "    with codecs.open(fileName,'w','utf8') as fp:\n",
    "        for item in proxyList:\n",
    "            fp.write(item.num + \"\\t\")\n",
    "            fp.write(item.title+ \"\\t\")\n",
    "            fp.write(item.author+ \"\\t\")\n",
    "            fp.write(item.bf + \"\\t\")\n",
    "            fp.write(item.count+ \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "data = []#存储日榜前100位up主的id号\n",
    "for line in open(\"F:/crawler_data/Bilibili/rank_id_list/\"+date+\"日榜up主id.txt\",\"r\"):\n",
    "    line = line[:-1]\n",
    "    data.append(line)\n",
    "path = 'F:/crawler_data/Bilibili/up_detail/'+date+'/'\n",
    "isExists=os.path.exists(path)\n",
    "if not isExists:\n",
    "    os.makedirs(path)\n",
    "    print(\"目录创建成功\")\n",
    "for j in data:\n",
    "    with open('F:/crawler_data/Bilibili/up_detail/'+date+'/'+j+'.csv', 'w', encoding='gb18030',errors='ignore') as file:\n",
    "        print(\"——正在爬取id为\"+j+\"的up主视频信息——\")\n",
    "        file.write(\"视频av号,视频标题,视频评论数,视频时长,视频观看量\")\n",
    "        file.write(\"\\n\")\n",
    "        up_detail = 'https://api.bilibili.com/x/space/acc/info?mid=%s&jsonp=jsonp'%j\n",
    "        up_fans = 'https://api.bilibili.com/x/relation/stat?vmid=%s&jsonp=jsonp'%j\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36 Edg/80.0.361.50'}\n",
    "        response_fans = requests.get(up_fans,headers = headers)\n",
    "        response_detail = requests.get(up_detail,headers = headers)\n",
    "\n",
    "        text_fans = json.loads(response_fans.text)\n",
    "        text_detail = json.loads((response_detail.text))\n",
    "\n",
    "        res_fans = text_fans['data']\n",
    "        follower = str(res_fans['follower'])  # up主个人的粉丝数\n",
    "\n",
    "        url_page = 'https://api.bilibili.com/x/space/arc/search?mid=%s&ps=30&tid=0&pn=1&keyword=&order=pubdate&jsonp=jsonp'%j\n",
    "        response_page = requests.get(url_page, headers=headers)\n",
    "        text_page = json.loads(response_page.text)\n",
    "        res_page = text_page['data']['page']\n",
    "        page = int(res_page['count'] / 30 + 1)#获取视频的页数\n",
    "\n",
    "        for i in range(1, page):\n",
    "            url = 'https://api.bilibili.com/x/space/arc/search?mid=%s&ps=30&tid=0&pn=%s&keyword=&order=pubdate&jsonp=jsonp'%(j,i)\n",
    "            response = requests.get(url, headers=headers)\n",
    "            text = json.loads(response.text)\n",
    "            res = text['data']['list']['vlist']\n",
    "            print(\"------正在爬取第-----\"+str(i)+\"-----页-----\")\n",
    "            for item in res:\n",
    "                title = str(item['title'])#视频标题\n",
    "                av = str(item['aid'])  # 视频av号\n",
    "                comment = str(item['comment'])  # 视频评论数\n",
    "                play = str(item['play'])  # 视频播放量\n",
    "                video_length = str(item['length'])  # 视频长度\n",
    "                file.write(\"{},{},{},{},{}\".format(av,title,comment,video_length,play))\n",
    "                file.write(\"\\n\")\n",
    "                print(\"-----正在爬取视频av号为：\" + av + \"的信息-----\")\n",
    "        print(\"-----完成-----\")\n",
    "        file.write(\"{}\".format(follower))\n",
    "        file.close()\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
