{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 高铁乘客数量预测\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.获取数据\n",
    "data = pd.read_csv(\"./train.csv\")\n",
    "data.head()\n",
    "# 2.数据处理\n",
    "# 2.1选择时间特征\n",
    "time = pd.to_datetime(data[\"datetime\"])\n",
    "time = pd.DatetimeIndex(time)\n",
    "data[\"day\"] = time.day\n",
    "data[\"hour\"] = time.hour\n",
    "data[\"weekday\"] = time.weekday\n",
    "data.head()\n",
    "# 2.2确定特征值和目标值\n",
    "x = data[[ \"hour\"]]\n",
    "y = data[\"cnt\"]\n",
    "# 2.3分割数据集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=22)\n",
    "# 3.特征工程--特征预处理(标准化)\n",
    "# 3.1 实例化一个转换器\n",
    "transfer = StandardScaler()\n",
    "# 3.2 调用fit_transform\n",
    "x_train = transfer.fit_transform(x_train)\n",
    "x_test = transfer.fit_transform(x_test)\n",
    "\n",
    "# estimator = SGDRegressor(max_iter=1000)\n",
    "# estimator.fit(x_train, y_train)\n",
    "# estimator = Ridge(alpha=1)\n",
    "estimator = RidgeCV(alphas=(0.1, 1, 10))\n",
    "estimator.fit(x_train, y_train)\n",
    "# 4.机器学习--knn+cv\n",
    "# 4.1 实例化一个估计器\n",
    "estimator = KNeighborsClassifier()\n",
    "# 4.2 调用gridsearchCV\n",
    "param_grid = {\"n_neighbors\": [1, 3, 5, 7, 9]}\n",
    "estimator = GridSearchCV(estimator, param_grid=param_grid, cv=5)\n",
    "# 4.3 模型训练\n",
    "estimator.fit(x_train, y_train)\n",
    "# 5.模型评估\n",
    "# 5.1 基本评估方式\n",
    "score = estimator.score(x_test, y_test)\n",
    "print(\"最后预测的准确率为:\\n\", score)\n",
    "\n",
    "y_predict = estimator.predict(x_test)\n",
    "print(\"最后的预测值为:\\n\", y_predict)\n",
    "print(\"预测值和真实值的对比情况:\\n\", y_predict == y_test)\n",
    "\n",
    "# 5.2 使用交叉验证后的评估方式\n",
    "print(\"在交叉验证中验证的最好结果:\\n\", estimator.best_score_)\n",
    "print(\"最好的参数模型:\\n\", estimator.best_estimator_)\n",
    "print(\"每次交叉验证后的验证集准确率结果和训练集准确率结果:\\n\",estimator.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import pywt\n",
    "import seaborn # seaborn与matlotlib同出一源，只是把matplotlib进行了封装，让许多方法调用时变得更加简便\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Activation\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN实现心电图预测\n",
    "# 小波去噪预处理\n",
    "RATIO=0.3  # 验证集占比\n",
    "def denoise(data):\n",
    "    # 小波变换\n",
    "    coeffs = pywt.wavedec(data=data, wavelet='db5', level=9)\n",
    "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
    "    # 阈值去噪\n",
    "    threshold = (np.median(np.abs(cD1)) / 0.6745) * (np.sqrt(2 * np.log(len(cD1))))\n",
    "    cD1.fill(0)\n",
    "    cD2.fill(0)\n",
    "    for i in range(1, len(coeffs) - 2):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold)\n",
    "    # 小波反变换,获取去噪后的信号\n",
    "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db5')\n",
    "    return rdata\n",
    "\n",
    "# 读取心电数据和对应标签,并对数据进行小波去噪\n",
    "def getDataSet(number, X_data, Y_data):\n",
    "    ecgClassSet = ['N', 'A', 'V', 'L', 'R']\n",
    "    \n",
    "    # 读取心电数据记录\n",
    "    # print(\"正在读取 \" + number + \" 号心电数据...\")\n",
    "    record = wfdb.rdrecord('./ecg_data/' + number, channel_names=['MLII'])\n",
    "    data = record.p_signal.flatten()\n",
    "    rdata = denoise(data=data)\n",
    "\n",
    "    # 获取心电数据记录中R波的位置和对应的标签\n",
    "    annotation = wfdb.rdann('ecg_data/' + number, 'atr')\n",
    "    Rlocation = annotation.sample\n",
    "    Rclass = annotation.symbol\n",
    "    #  数据读取完成\n",
    "    \n",
    "    # 去掉前后的不稳定数据\n",
    "    start = 10\n",
    "    end = 5\n",
    "    i = start\n",
    "    j = len(annotation.symbol) - end\n",
    "\n",
    "    # 因为只选择NAVLR五种心电类型,所以要选出该条记录中所需要的那些带有特定标签的数据,舍弃其余标签的点\n",
    "    # X_data在R波前后截取长度为300的数据点\n",
    "    # Y_data将NAVLR按顺序转换为01234\n",
    "    while i < j:\n",
    "        try:\n",
    "            lable = ecgClassSet.index(Rclass[i])   \n",
    "            x_train = rdata[Rlocation[i] - 99:Rlocation[i] + 201]\n",
    "            X_data.append(x_train)\n",
    "            Y_data.append(lable)\n",
    "            i += 1\n",
    "        except ValueError:\n",
    "            i += 1\n",
    "    return\n",
    "\n",
    "\n",
    "# 加载数据集并进行预处理\n",
    "def loadData():\n",
    "    numberSet = ['100', '101', '103', '105', '106', '107', '108', '109', '111', '112', '113', '114', '115',\n",
    "                 '116', '117', '119', '121', '122', '123', '124', '200', '201', '202', '203', '205', '208',\n",
    "                 '210', '212', '213', '214', '215', '217', '219', '220', '221', '222', '223', '228', '230',\n",
    "                 '231', '232', '233', '234']\n",
    "    dataSet = []\n",
    "    lableSet = []\n",
    "    for n in numberSet:\n",
    "        getDataSet(n, dataSet, lableSet)\n",
    "    # 转numpy数组,打乱顺序\n",
    "    dataSet = np.array(dataSet).reshape(-1, 300)   # 转换成numpy数组\n",
    "    lableSet = np.array(lableSet).reshape(-1, 1)\n",
    "    train_ds = np.hstack((dataSet, lableSet))\n",
    "    np.random.shuffle(train_ds)  # 打乱顺序，通过换行使得形式\n",
    "\n",
    "#     # 数据集及其标签集\n",
    "    X = train_ds[:, :300].reshape(-1, 300, 1)\n",
    "    Y = train_ds[:, 300]\n",
    "\n",
    "#     # 测试集及其标签集\n",
    "    shuffle_index = np.random.permutation(len(X))\n",
    "    test_length = int(RATIO * len(shuffle_index))\n",
    "    test_index = shuffle_index[:test_length]\n",
    "    train_index = shuffle_index[test_length:]\n",
    "    X_test, Y_test = X[test_index], Y[test_index]\n",
    "    X_train, Y_train = X[train_index], Y[train_index]\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(dataSet,lableSet,test_size=0.3,shuffle=False)   # shuffle=False乱序\n",
    "    X_train = np.array( X_train).reshape(-1, 300,1)\n",
    "    X_test = np.array( X_test).reshape(-1, 300,1)\n",
    "    Y_train = np.array( Y_train).reshape(-1,1)\n",
    "    Y_test = np.array(Y_test).reshape(-1,1)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "# [X_train,X_test,Y_train,Y_test]=loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 300, 4)            88        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 150, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 150, 16)           14800     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 75, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 75, 32)            12832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 38, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 38, 64)            43072     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               311424    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 382,861\n",
      "Trainable params: 382,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN模型构建\n",
    "model = Sequential()\n",
    "# 第一个卷积层, 4 个 21x1 卷积核\n",
    "model.add(Conv1D(filters=4, kernel_size=21, strides=1, padding='SAME', activation='relu',input_shape=(300, 1)))\n",
    "# 第一个池化层, 最大池化,4 个 3x1 卷积核, 步长为 2\n",
    "model.add(MaxPooling1D(pool_size=3, strides=2, padding='SAME'))\n",
    "# 第二个卷积层, 16 个 23x1 卷积核\n",
    "model.add(Conv1D(filters=16, kernel_size=231, strides=1, padding='SAME', activation='relu'))\n",
    "# 第二个池化层, 最大池化,4 个 3x1 卷积核, 步长为 2\n",
    "model.add(MaxPooling1D(pool_size=3, strides=2, padding='SAME'))\n",
    " # 第三个卷积层, 32 个 25x1 卷积核\n",
    "model.add(Conv1D(filters=32, kernel_size=25, strides=1, padding='SAME', activation='relu'))\n",
    "# 第三个池化层, 平均池化,4 个 3x1 卷积核, 步长为 2\n",
    "model.add(MaxPooling1D(pool_size=3, strides=2, padding='SAME'))\n",
    "# 第四个卷积层, 64 个 27x1 卷积核\n",
    "model.add(Conv1D(filters=64, kernel_size=21, strides=1, padding='SAME', activation='relu'))\n",
    "# 打平层,方便全连接层处理\n",
    "model.add(Flatten())\n",
    "# 全连接层,128 个节点\n",
    "model.add(Dense(128))\n",
    "# Dropout层,dropout = 0.2  随机冻结20%的权重，防止过拟合\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "# 全连接层,5 个节点  输出层\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "# 损失函数，优化器，精度\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测\n",
    "history = model.fit(X_train, Y_train, epochs=2,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(1,len(acc) + 1)\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.title('Training  accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.title('Training  loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(history.history.keys())\n",
    "print(model.evaluate(x_test,one_hot_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model.predict(X_test)\n",
    "Y_pred = model.predict_classes(X_test)\n",
    "# plt.plot(Y_test[:100])\n",
    "con_mat = confusion_matrix(Y_test, Y_pred)\n",
    "    # 归一化\n",
    "    # con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "    # con_mat_norm = np.around(con_mat_norm, decimals=2)\n",
    "    # 绘图\n",
    "plt.figure(figsize=(8, 8))\n",
    "seaborn.heatmap(con_mat, annot=True, fmt='.20g', cmap='Blues')\n",
    "plt.ylim(0, 5)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入第一个数：55\n",
      "请输入第二个数：54\n",
      "请输入第三个数：53\n",
      "55 54 53\n"
     ]
    }
   ],
   "source": [
    "# 判断任意3个数的大小，按从大到小排列\n",
    "a=input(\"请输入第一个数：\")\n",
    "b=input(\"请输入第二个数：\")\n",
    "c=input(\"请输入第三个数：\")\n",
    "a=int(a)\n",
    "b=int(b)\n",
    "c=int(c)\n",
    "if a>b>c:\n",
    "    print(a,b,c)\n",
    "elif a>c>b:\n",
    "    d=c;c=b;b=d\n",
    "    print(a,b,c)\n",
    "elif b>a>c:\n",
    "    d=b;b=a;a=d\n",
    "    print(a,b,c)\n",
    "elif b>c>a:\n",
    "    d=b;e=c;b=e;c=a;a=d\n",
    "    print(a,b,c)\n",
    "elif c>a>b:\n",
    "    d=c;e=a;f=b;c=f;b=e;a=d\n",
    "    print(a,b,c)\n",
    "elif c>b>a:\n",
    "    d=c;c=a;a=d\n",
    "    print(a,b,c)\n",
    "else:\n",
    "    print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入年份：2030\n",
      "2030年不是闰年\n"
     ]
    }
   ],
   "source": [
    "# 判断闰年\n",
    "i=int(input(\"请输入年份：\"))\n",
    "if ((i%4==0) and (i%100!=0)):\n",
    "    print(\"%d年是闰年\"%i)\n",
    "else:\n",
    "    print(\"%d年不是闰年\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入您的成绩：555\n",
      "wrong score .must between 0 and 100.\n",
      "请输入您的成绩：99\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "# 成绩按等级划分\n",
    "score=int(input(\"请输入您的成绩：\"))\n",
    "def func(score):\n",
    "    if score >100 or score <=0:\n",
    "        return\"wrong score .must between 0 and 100.\"\n",
    "    elif score >= 90:\n",
    "        return\"A\"\n",
    "    elif score >= 80:\n",
    "        return \"B\"\n",
    "    elif score >= 70:\n",
    "        return \"C\"\n",
    "    elif score >=60:\n",
    "        return \"D\"\n",
    "    else:\n",
    "        return \"E\"\n",
    "print(func(score))\n",
    "# 或者用嵌套选择结构\n",
    "score=int(input(\"请输入您的成绩：\"))\n",
    "def func(score):\n",
    "    degree = \"DCBAAE\"\n",
    "    if score >100 or score <=0:\n",
    "        return\"wrong score .must between 0 and 100.\"\n",
    "    else:\n",
    "        index =(score-60)//10\n",
    "        if index >= 0:\n",
    "            return degree[index]\n",
    "        else:\n",
    "            return[-1]\n",
    "print(func(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050\n",
      "5050\n"
     ]
    }
   ],
   "source": [
    "s=0;n=1\n",
    "while n<=100:\n",
    "    s=s+n\n",
    "    n=n+1 \n",
    "print(s)\n",
    "# 或者用for-else语句配合使用\n",
    "s=0\n",
    "for i in range(1,101):\n",
    "    s=s+i\n",
    "else:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
